{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SobanRaza_058_B",
      "provenance": [],
      "collapsed_sections": [
        "quDdEadW8PBu",
        "2n4FcrzV8Xxm",
        "PK6uwZtq7bVI"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzzTQD-Z6luX"
      },
      "source": [
        "# SentiMix Hindi-English\n",
        "\n",
        "[Competition Link](https://competitions.codalab.org/competitions/20654)\n",
        "\n",
        "[Preprocessed Training Set](https://drive.google.com/file/d/1VJwEz8Er32HVU9cRT0KE6_aQ57Zk1KHn/view?usp=sharing)\n",
        "\n",
        "[Preprocessed Test Set](https://drive.google.com/file/d/1fEStOFdGeowWemE0uw_UOm9TfeTcxmbh/view?usp=sharing) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mHgfS_n6yqi"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX0IP_-QLvh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c4162e-0a8f-4c37-ae76-7d29b1efdd89"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aX7lQWPKllt"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import transformers\n",
        "\n",
        "import regex as re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import style\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "import torch\n",
        "from torch import tensor\n",
        "from transformers import BertTokenizer, BertConfig, BertForSequenceClassification, AdamW, Adafactor, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "style.use('dark_background')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg7mgUD6IRz2"
      },
      "source": [
        "# Useful paths\n",
        "DRIVE_DIR = '/content/drive'\n",
        "DATA_DIR = os.path.join(DRIVE_DIR, 'My Drive/sentimix')\n",
        "TRAIN_DATA_PATH = os.path.join(DATA_DIR, 'train_set_without_usernames.json')\n",
        "TEST_DATA_PATH = os.path.join(DATA_DIR, 'test_set_without_usernames.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuYXBClDKDAA",
        "outputId": "e29e9759-876a-4e8b-aa3f-e9d86950f19e"
      },
      "source": [
        "# Mounting drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(DRIVE_DIR)\n",
        "%cd $DATA_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/1mNIgpMsgysDwuZSrrcFW0VHemZmuiHA8/sentimix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdp2myl869NO"
      },
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoVo77uFUCcR"
      },
      "source": [
        "# Loading datasets\n",
        "train_data = pd.read_json(TRAIN_DATA_PATH).T\n",
        "test_data = pd.read_json(TEST_DATA_PATH).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "snduGIjRVfva",
        "outputId": "6d69e5ef-8bcd-4d01-ec5f-69e8f4a36045"
      },
      "source": [
        "train_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>[pakistan, ka, ghra, tauq, he, pakistan, israe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>negative</td>\n",
              "      <td>[madarchod, mulle, ye, mathura, me, nahi, dikh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>positive</td>\n",
              "      <td>[manya, pradhan, mantri, mahoday, shriman, nar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>positive</td>\n",
              "      <td>[_, krishna, jcb, full, trend, me, chal, rahi,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>positive</td>\n",
              "      <td>[_, loksabha, me, janta, sirf, modi, ko, vote,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>negative</td>\n",
              "      <td>[bhosdike, tum, pechvade, ki, tatti, hi, rahog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>positive</td>\n",
              "      <td>[love, u, bhaijan, father, son, bharat, iambha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>negative</td>\n",
              "      <td>[tumhara, pass, abh, deemagh, hai, nahi, islea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>positive</td>\n",
              "      <td>[_, nolo, weni, ankere, o, gae, this, weekend, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>negative</td>\n",
              "      <td>[_, aimim, lage, raho, mullo, tumhre, issi, qu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                           sentence\n",
              "3    negative  [pakistan, ka, ghra, tauq, he, pakistan, israe...\n",
              "41   negative  [madarchod, mulle, ye, mathura, me, nahi, dikh...\n",
              "48   positive  [manya, pradhan, mantri, mahoday, shriman, nar...\n",
              "64   positive  [_, krishna, jcb, full, trend, me, chal, rahi,...\n",
              "66   positive  [_, loksabha, me, janta, sirf, modi, ko, vote,...\n",
              "68   negative  [bhosdike, tum, pechvade, ki, tatti, hi, rahog...\n",
              "90   positive  [love, u, bhaijan, father, son, bharat, iambha...\n",
              "99   negative  [tumhara, pass, abh, deemagh, hai, nahi, islea...\n",
              "101  positive   [_, nolo, weni, ankere, o, gae, this, weekend, ]\n",
              "104  negative  [_, aimim, lage, raho, mullo, tumhre, issi, qu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKf16ViLV1v2",
        "outputId": "6e314d09-ada4-4d2c-8500-4f5dec0ec4ef"
      },
      "source": [
        "train_data['sentiment'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       15480\n",
              "unique          3\n",
              "top       neutral\n",
              "freq         5787\n",
              "Name: sentiment, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "B_35s2RUXwVl",
        "outputId": "2cebb291-80e2-4355-9bd7-6f4367e28768"
      },
      "source": [
        "train_data['sentiment'].value_counts().sort_values().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f906f0bd5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXYDsS1XDNKT"
      },
      "source": [
        "# Converting label strings to numeric labels\n",
        "labels = {'negative': 0, 'positive': 1, 'neutral': 2}\n",
        "train_data['sentiment'] = train_data['sentiment'].replace(labels)\n",
        "test_data['sentiment'] = test_data['sentiment'].replace(labels)\n",
        "\n",
        "train_data['sentence'] = train_data['sentence'].apply(lambda tokens: ' '.join(tokens).strip())\n",
        "test_data['sentence'] = test_data['sentence'].apply(lambda tokens: ' '.join(tokens).strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PspiNcNZ7kLf"
      },
      "source": [
        "## Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnHIkqm-4zSO"
      },
      "source": [
        "NUM_WORKERS = 2\n",
        "\n",
        "# A function to create a data loader given a tokenizer, a sampler, the sentences,\n",
        "# their labels and the batch size. Sentences are passed in without being tokenized.\n",
        "# A dataloader providing input ids, attention masks and labels is created\n",
        "def create_data_loader(tokenizer, sampler, sentences, labels, batch_size):\n",
        "    encoded = tokenizer(\n",
        "        text=sentences,\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        pad_to_multiple_of=8,\n",
        "        return_tensors='pt',\n",
        "        padding='longest'\n",
        "    )\n",
        "\n",
        "    input_ids = encoded['input_ids']\n",
        "    attention_masks = encoded['attention_mask']\n",
        "    labels = tensor(labels)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    return DataLoader(\n",
        "        dataset, \n",
        "        sampler=sampler(dataset),\n",
        "        batch_size=batch_size, \n",
        "        num_workers=NUM_WORKERS\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXZyJA5I5don"
      },
      "source": [
        "# Creating data loaders for training and test set\n",
        "BATCH_SIZE = 96\n",
        "MODEL_NAME = 'DeepPavlov/bert-base-multilingual-cased-sentence'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_loader = create_data_loader(\n",
        "    tokenizer, \n",
        "    RandomSampler,\n",
        "    train_data['sentence'].values.tolist(),\n",
        "    train_data['sentiment'].values,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_loader = create_data_loader(\n",
        "    tokenizer, \n",
        "    SequentialSampler,\n",
        "    test_data['sentence'].values.tolist(),\n",
        "    test_data['sentiment'].values,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TffgxsLg7okU"
      },
      "source": [
        "## Defining Training & Eval Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HmbVlShioSY"
      },
      "source": [
        "# A function to set the random seed value\n",
        "def set_seed(seed_value=42):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtuvES7SUH7L"
      },
      "source": [
        "# A function to evaluate a model on a data loader\n",
        "def eval_model(model, loader, device):\n",
        "    model = model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            inputs = {\n",
        "                'input_ids': batch[0].to(device),\n",
        "                'attention_mask': batch[1].to(device),\n",
        "                'labels': batch[2].to(device)\n",
        "            }\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits.detach().cpu()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predictions.append(torch.argmax(logits, dim=1))\n",
        "            true_labels.append(inputs['labels'].cpu().numpy())\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "    return total_loss / len(loader), true_labels, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNs-JKcQvA0R"
      },
      "source": [
        "# A function to train one epoch of a model on a data loader (tloader)\n",
        "# and return F1 score of the model on another data loader (dloader)\n",
        "def train_epoch(model, tloader, dloader, optimizer, scheduler, device):\n",
        "    model = model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    tqdm_bar = tqdm(tloader)\n",
        "    for batch in tqdm_bar:\n",
        "        optimizer.zero_grad()\n",
        "        inputs = {\n",
        "            'input_ids': batch[0].to(device),\n",
        "            'attention_mask': batch[1].to(device),\n",
        "            'labels': batch[2].to(device)\n",
        "        }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        tqdm_bar.set_postfix({'TRAINING LOSS': '{:.8f}'.format(loss.item() / len(batch))})\n",
        "\n",
        "    dev_loss, dev_true_labels, dev_predictions = eval_model(model, dloader, device)\n",
        "    print(f'AVERAGE TRAINING LOSS: {total_loss / len(tloader)}')\n",
        "    print(f'AVERAGE TEST LOSS: {dev_loss}')\n",
        "    print(f'WEIGHTED TEST F1 SCORE: {f1_score(dev_true_labels, dev_predictions, average=\"weighted\")}')\n",
        "\n",
        "    return f1_score(dev_true_labels, dev_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_kqdIpr7uOq"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjP6fLSD_BEt"
      },
      "source": [
        "# Training the model\n",
        "EPOCHS = 4\n",
        "\n",
        "set_seed(11)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, \n",
        "    num_labels=len(labels), \n",
        "    output_attentions=True,\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = Adafactor(\n",
        "    model.parameters(),\n",
        "    lr=4e-5,\n",
        "    eps=(1e-30, 1e-3),\n",
        "    clip_threshold=1.0,\n",
        "    decay_rate=-0.8,\n",
        "    beta1=None,\n",
        "    weight_decay=0.0,\n",
        "    relative_step=False,\n",
        "    scale_parameter=False,\n",
        "    warmup_init=False\n",
        ")\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps=0.1 * len(train_loader), \n",
        "    num_training_steps=EPOCHS * len(train_loader)\n",
        ")\n",
        "\n",
        "test_f1 = -math.inf\n",
        "for epoch in range(EPOCHS):\n",
        "    hold_f1 = train_epoch(model, train_loader, test_loader, optimizer, scheduler, device)\n",
        "\n",
        "    if hold_f1 > test_f1:\n",
        "        torch.save(model.state_dict(), f'{DATA_DIR}/bert_sentimix.bin')\n",
        "        print(f'FOUND A BEST MODEL WITH TEST DATA F1 SCORE OF {hold_f1}')\n",
        "        test_f1 = hold_f1\n",
        "        \n",
        "del model\n",
        "del optimizer\n",
        "del scheduler\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quDdEadW8PBu"
      },
      "source": [
        "## Loading Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg-jzmnzPpky"
      },
      "source": [
        "# Loading a trained from GDrive\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model_eval = BertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(labels),\n",
        "    output_attentions=False\n",
        ")\n",
        "\n",
        "model_eval.to(device)\n",
        "\n",
        "model_eval.load_state_dict(torch.load(f'{DATA_DIR}/0.7052.bin', map_location=torch.device('cpu')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkDkN8hoXblA"
      },
      "source": [
        "# Calculating Training F1 Score\n",
        "train_loss, train_true_labels, train_predictions = eval_model(model_eval, train_loader, device)\n",
        "f1_score(train_true_labels, train_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0OyDStQOnPq"
      },
      "source": [
        "# Calculating Test F1 Score\n",
        "test_loss, test_true_labels, test_predictions = eval_model(model_eval, test_loader, device)\n",
        "f1_score(test_true_labels, test_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pawob9TzCHf"
      },
      "source": [
        "# Printing Test Classification Report\n",
        "print(classification_report(test_true_labels, test_predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n4FcrzV8Xxm"
      },
      "source": [
        "## Generating Answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DtrJWN6M_px"
      },
      "source": [
        "# Generating answer.txt as specified in the event details\n",
        "labels_inv = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
        "\n",
        "with open(f'{DATA_DIR}/answer.txt', 'w') as ofile:\n",
        "    i = 0\n",
        "    ofile.write('Uid,Sentiment\\n')\n",
        "    for idx, row in test_data.iterrows():\n",
        "        ofile.write(f'{idx},{labels_inv[test_predictions[i]]}\\n')\n",
        "        i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK6uwZtq7bVI"
      },
      "source": [
        "## Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsjR1BcVFkH5"
      },
      "source": [
        "# Drop all the text after 'https' substring is encountered\n",
        "def drop_after_https(text):\n",
        "    return text.split('https')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UJT6dUwCNqM"
      },
      "source": [
        "# A function to remove all numbers from the provided text\n",
        "def remove_numbers(text):\n",
        "    return ''.join([x for x in text if not x.isdigit()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ4xZIfVZu7S"
      },
      "source": [
        "# A function to remove emojis from the provided text\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(pattern='['\n",
        "        \"\\U0001F600-\\U0001F64F\"\n",
        "        \"\\U0001F300-\\U0001F5FF\"\n",
        "        \"\\U0001F680-\\U0001F6FF\"\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"\n",
        "        ']+', flags=re.UNICODE)\n",
        "    \n",
        "    return emoji_pattern.sub('', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iAwi1KKCvTL"
      },
      "source": [
        "# Remove all the mentions from the tweets\n",
        "def remove_mentions(text):\n",
        "    return re.sub(r'@ \\w+', '', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzf82D_OBOIg"
      },
      "source": [
        "# A function to remove all punctuation from the provided text\n",
        "def remove_punctuations(text):\n",
        "    punctuation_pattern = re.compile(pattern='[^\\w\\s]', flags=re.UNICODE)\n",
        "    return punctuation_pattern.sub('', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KefdrJfHRxe"
      },
      "source": [
        "# A function to collapse multiple consecutive whitespaces into one space\n",
        "def collapse_whitespaces(text):\n",
        "    whitespaces_pattern = re.compile(pattern='\\s+', flags=re.UNICODE)\n",
        "    return whitespaces_pattern.sub(' ', text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}